{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "598faafe",
   "metadata": {},
   "source": [
    "# How to compute Mahalanobis Distance in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39baa1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>61.5</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>59.8</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>56.9</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>62.4</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>63.3</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat  depth  price\n",
       "0   0.23   61.5    326\n",
       "1   0.21   59.8    326\n",
       "2   0.23   56.9    327\n",
       "3   0.29   62.4    334\n",
       "4   0.31   63.3    335"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import scipy.linalg as sp_la\n",
    "\n",
    "filepath = 'https://raw.githubusercontent.com/selva86/datasets/master/diamonds.csv'\n",
    "df = pd.read_csv(filepath).iloc[:, [0,4,6]]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a570e4f0",
   "metadata": {},
   "source": [
    "Let’s write the function to calculate Mahalanobis Distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4189eea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>price</th>\n",
       "      <th>mahala</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>61.5</td>\n",
       "      <td>326</td>\n",
       "      <td>1.709860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>59.8</td>\n",
       "      <td>326</td>\n",
       "      <td>3.540097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>56.9</td>\n",
       "      <td>327</td>\n",
       "      <td>12.715021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>62.4</td>\n",
       "      <td>334</td>\n",
       "      <td>1.454469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>63.3</td>\n",
       "      <td>335</td>\n",
       "      <td>2.347239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat  depth  price     mahala\n",
       "0   0.23   61.5    326   1.709860\n",
       "1   0.21   59.8    326   3.540097\n",
       "2   0.23   56.9    327  12.715021\n",
       "3   0.29   62.4    334   1.454469\n",
       "4   0.31   63.3    335   2.347239"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mahalanobis(x=None, data=None, cov=None):\n",
    "    \"\"\"Compute the Mahalanobis Distance between each row of x and the data  \n",
    "    x    : vector or matrix of data with, say, p columns.\n",
    "    data : ndarray of the distribution from which Mahalanobis distance of each observation of x is to be computed.\n",
    "    cov  : covariance matrix (p x p) of the distribution. If None, will be computed from data.\n",
    "    \"\"\"\n",
    "    x_minus_mu = x - np.mean(data)\n",
    "    if not cov:\n",
    "        cov = np.cov(data.values.T)\n",
    "    inv_covmat = sp.linalg.inv(cov)\n",
    "    left_term = np.dot(x_minus_mu, inv_covmat)\n",
    "    mahal = np.dot(left_term, x_minus_mu.T)\n",
    "    return mahal.diagonal()\n",
    "\n",
    "df_x = df[['carat', 'depth', 'price']].head(500)\n",
    "df_x['mahala'] = mahalanobis(x=df_x, data=df[['carat', 'depth', 'price']])\n",
    "df_x.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db91d1ce",
   "metadata": {},
   "source": [
    "# Usecase 1: Multivariate outlier detection using Mahalanobis distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f216bb",
   "metadata": {},
   "source": [
    "Assuming that the test statistic follows chi-square distributed with ‘n’ degree of freedom, the critical value at a 0.01 significance level and 2 degrees of freedom is computed as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f645597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.21034037197618"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Critical values for two degrees of freedom\n",
    "from scipy.stats import chi2\n",
    "chi2.ppf((1-0.01), df=2)\n",
    "#> 9.21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e51c37",
   "metadata": {},
   "source": [
    "That mean an observation can be considered as extreme if its Mahalanobis distance exceeds 9.21.\n",
    "\n",
    "If you prefer P values instead to determine if an observation is extreme or not, the P values can be computed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faf16d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>price</th>\n",
       "      <th>mahala</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>56.9</td>\n",
       "      <td>327</td>\n",
       "      <td>12.715021</td>\n",
       "      <td>0.001734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.86</td>\n",
       "      <td>55.1</td>\n",
       "      <td>2757</td>\n",
       "      <td>23.909643</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.96</td>\n",
       "      <td>66.3</td>\n",
       "      <td>2759</td>\n",
       "      <td>11.781773</td>\n",
       "      <td>0.002765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.17</td>\n",
       "      <td>60.2</td>\n",
       "      <td>2774</td>\n",
       "      <td>9.279459</td>\n",
       "      <td>0.009660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.98</td>\n",
       "      <td>67.9</td>\n",
       "      <td>2777</td>\n",
       "      <td>20.086616</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.70</td>\n",
       "      <td>57.2</td>\n",
       "      <td>2782</td>\n",
       "      <td>10.405659</td>\n",
       "      <td>0.005501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.84</td>\n",
       "      <td>55.1</td>\n",
       "      <td>2782</td>\n",
       "      <td>23.548379</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1.05</td>\n",
       "      <td>65.8</td>\n",
       "      <td>2789</td>\n",
       "      <td>11.237146</td>\n",
       "      <td>0.003630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>1.00</td>\n",
       "      <td>58.2</td>\n",
       "      <td>2795</td>\n",
       "      <td>10.349019</td>\n",
       "      <td>0.005659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1.01</td>\n",
       "      <td>67.4</td>\n",
       "      <td>2797</td>\n",
       "      <td>17.716144</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     carat  depth  price     mahala   p_value\n",
       "2     0.23   56.9    327  12.715021  0.001734\n",
       "91    0.86   55.1   2757  23.909643  0.000006\n",
       "97    0.96   66.3   2759  11.781773  0.002765\n",
       "172   1.17   60.2   2774   9.279459  0.009660\n",
       "204   0.98   67.9   2777  20.086616  0.000043\n",
       "221   0.70   57.2   2782  10.405659  0.005501\n",
       "227   0.84   55.1   2782  23.548379  0.000008\n",
       "255   1.05   65.8   2789  11.237146  0.003630\n",
       "284   1.00   58.2   2795  10.349019  0.005659\n",
       "298   1.01   67.4   2797  17.716144  0.000142"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the P-Values\n",
    "df_x['p_value'] = 1 - chi2.cdf(df_x['mahala'], 2)\n",
    "\n",
    "# Extreme values with a significance level of 0.01\n",
    "df_x.loc[df_x.p_value < 0.01].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0913f85e",
   "metadata": {},
   "source": [
    "If you compare the above observations against rest of the dataset, they are clearly extreme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4f2852",
   "metadata": {},
   "source": [
    "# Usecase 2: Mahalanobis Distance for Classification Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641e53d6",
   "metadata": {},
   "source": [
    "Mahalanobis distance can be used for classification problems. A naive implementation of a Mahalanobis classifier is coded below. The intuition is that, an observation is assigned the class that it is closest to based on the Mahalanobis distance.\n",
    "\n",
    "Let’s see an example implementation on the BreastCancer dataset, where the objective is to determine if a tumour is benign or malignant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2f80bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cl.thickness</th>\n",
       "      <th>Cell.size</th>\n",
       "      <th>Marg.adhesion</th>\n",
       "      <th>Epith.c.size</th>\n",
       "      <th>Bare.nuclei</th>\n",
       "      <th>Bl.cromatin</th>\n",
       "      <th>Normal.nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cl.thickness  Cell.size  Marg.adhesion  Epith.c.size  Bare.nuclei  \\\n",
       "0             5          1              1             2          1.0   \n",
       "1             5          4              5             7         10.0   \n",
       "2             3          1              1             2          2.0   \n",
       "3             6          8              1             3          4.0   \n",
       "4             4          1              3             2          1.0   \n",
       "\n",
       "   Bl.cromatin  Normal.nucleoli  Mitoses  Class  \n",
       "0            3                1        1      0  \n",
       "1            3                2        1      0  \n",
       "2            3                1        1      0  \n",
       "3            3                7        1      0  \n",
       "4            3                1        1      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BreastCancer.csv', \n",
    "                 usecols=['Cl.thickness', 'Cell.size', 'Marg.adhesion', \n",
    "                          'Epith.c.size', 'Bare.nuclei', 'Bl.cromatin', 'Normal.nucleoli', \n",
    "                          'Mitoses', 'Class'])\n",
    "\n",
    "df.dropna(inplace=True)  # drop missing values.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e8c2e7",
   "metadata": {},
   "source": [
    "Let’s split the dataset in 70:30 ratio as Train and Test. And the training dataset is split into homogeneous groups of ‘pos'(1) and ‘neg'(0) classes. To predict the class of the test dataset, we measure the Mahalanobis distances between a given observation (row) and both the positive (xtrain_pos) and negative datasets(xtrain_neg).\n",
    "\n",
    "Then that observation is assigned the class based on the group it is closest to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3827701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df.drop('Class', axis=1), df['Class'], test_size=.3, random_state=100)\n",
    "\n",
    "# Split the training data as pos and neg\n",
    "xtrain_pos = xtrain.loc[ytrain == 1, :]\n",
    "xtrain_neg = xtrain.loc[ytrain == 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467900f3",
   "metadata": {},
   "source": [
    "Let’s build the MahalanobiBinaryClassifier. To do that, you need to define the predict_proba() and the predict() methods. This classifier does not require a separate fit() (training) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08d64791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pred  true\n",
      "0     0     0\n",
      "1     1     1\n",
      "2     0     0\n",
      "3     0     0\n",
      "4     0     0\n"
     ]
    }
   ],
   "source": [
    "class MahalanobisBinaryClassifier():\n",
    "    def __init__(self, xtrain, ytrain):\n",
    "        self.xtrain_pos = xtrain.loc[ytrain == 1, :]\n",
    "        self.xtrain_neg = xtrain.loc[ytrain == 0, :]\n",
    "\n",
    "    def predict_proba(self, xtest):\n",
    "        pos_neg_dists = [(p,n) for p, n in zip(mahalanobis(xtest, self.xtrain_pos), mahalanobis(xtest, self.xtrain_neg))]\n",
    "        return np.array([(1-n/(p+n), 1-p/(p+n)) for p,n in pos_neg_dists])\n",
    "\n",
    "    def predict(self, xtest):\n",
    "        return np.array([np.argmax(row) for row in self.predict_proba(xtest)])\n",
    "\n",
    "\n",
    "clf = MahalanobisBinaryClassifier(xtrain, ytrain)        \n",
    "pred_probs = clf.predict_proba(xtest)\n",
    "pred_class = clf.predict(xtest)\n",
    "\n",
    "# Pred and Truth\n",
    "pred_actuals = pd.DataFrame([(pred, act) for pred, act in zip(pred_class, ytest)], columns=['pred', 'true'])\n",
    "print(pred_actuals[:5])       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d053d",
   "metadata": {},
   "source": [
    "Let’s see how the classifier performed on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3a71fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC:  0.990974358974359\n",
      "\n",
      "Confusion Matrix: \n",
      " [[113  17]\n",
      " [  0  75]]\n",
      "\n",
      "Accuracy Score:  0.9170731707317074\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93       130\n",
      "           1       0.82      1.00      0.90        75\n",
      "\n",
      "    accuracy                           0.92       205\n",
      "   macro avg       0.91      0.93      0.91       205\n",
      "weighted avg       0.93      0.92      0.92       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
    "truth = pred_actuals.loc[:, 'true']\n",
    "pred = pred_actuals.loc[:, 'pred']\n",
    "scores = np.array(pred_probs)[:, 1]\n",
    "print('AUROC: ', roc_auc_score(truth, scores))\n",
    "print('\\nConfusion Matrix: \\n', confusion_matrix(truth, pred))\n",
    "print('\\nAccuracy Score: ', accuracy_score(truth, pred))\n",
    "print('\\nClassification Report: \\n', classification_report(truth, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad44f5e7",
   "metadata": {},
   "source": [
    "Mahalanobis distance alone is able to contribute to this much accuracy (92%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203e5745",
   "metadata": {},
   "source": [
    "# Usecase 3: One-Class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9bbc90",
   "metadata": {},
   "source": [
    "One Class classification is a type of algorithm where the training dataset contains observations belonging to only one class.\n",
    "\n",
    "With only that information known, the objective is to figure out if a given observation in a new (or test) dataset belongs to that class.\n",
    "\n",
    "You might wonder when would such a situation occur. Well, it’s a quite common problem in Data Science.\n",
    "\n",
    "For example consider the following situation: You have a large dataset containing millions of records that are NOT yet categorized as 1’s and 0’s. But you also have with you a small sample dataset containing only positive (1’s) records. By learning the information in this sample dataset, you want to classify all the records in the large dataset as 1’s and 0’s.\n",
    "\n",
    "Based on the information from the sample dataset, it is possible to tell if any given sample is a 1 or 0 by viewing only the 1’s (and having no knowledge of the 0’s at all).\n",
    "\n",
    "This can be done using Mahalanobis Distance.\n",
    "\n",
    "Let’s try this on the BreastCancer dataset, only this time we will consider only the malignant observations (class column=1) in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88e0fec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BreastCancer.csv', \n",
    "                 usecols=['Cl.thickness', 'Cell.size', 'Marg.adhesion', \n",
    "                          'Epith.c.size', 'Bare.nuclei', 'Bl.cromatin', 'Normal.nucleoli', \n",
    "                          'Mitoses', 'Class'])\n",
    "\n",
    "df.dropna(inplace=True)  # drop missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ccc02",
   "metadata": {},
   "source": [
    "Splitting 50% of the dataset into training and test. Only the 1’s are retained in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e24578f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df.drop('Class', axis=1), df['Class'], test_size=.5, random_state=100)\n",
    "\n",
    "# Split the training data as pos and neg\n",
    "xtrain_pos = xtrain.loc[ytrain == 1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf632ab",
   "metadata": {},
   "source": [
    "Let’s build the MahalanobisOneClassClassifier and get the mahalanobis distance of each datapoint in x from the training set (xtrain_pos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1311a06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical value is:  14.067140449340169\n",
      "       mahal  true_class\n",
      "0  13.104716           0\n",
      "1  14.408570           1\n",
      "2  14.932236           0\n",
      "3  14.588622           0\n",
      "4  15.471064           0\n"
     ]
    }
   ],
   "source": [
    "class MahalanobisOneclassClassifier():\n",
    "    def __init__(self, xtrain, significance_level=0.01):\n",
    "        self.xtrain = xtrain\n",
    "        self.critical_value = chi2.ppf((1-significance_level), df=xtrain.shape[1]-1)\n",
    "        print('Critical value is: ', self.critical_value)\n",
    "\n",
    "    def predict_proba(self, xtest):\n",
    "        mahalanobis_dist = mahalanobis(xtest, self.xtrain)\n",
    "        self.pvalues = 1 - chi2.cdf(mahalanobis_dist, 2)\n",
    "        return mahalanobis_dist\n",
    "\n",
    "    def predict(self, xtest):\n",
    "        return np.array([int(i) for i in self.predict_proba(xtest) > self.critical_value])\n",
    "\n",
    "clf = MahalanobisOneclassClassifier(xtrain_pos, significance_level=0.05)\n",
    "mahalanobis_dist = clf.predict_proba(xtest)\n",
    "\n",
    "# Pred and Truth\n",
    "mdist_actuals = pd.DataFrame([(m, act) for m, act in zip(mahalanobis_dist, ytest)], columns=['mahal', 'true_class'])\n",
    "print(mdist_actuals[:5])          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f31a90",
   "metadata": {},
   "source": [
    "We have the Mahalanobis distance and the actual class of each observation.\n",
    "\n",
    "I would expect those observations with low Mahalanobis distance to be 1’s.\n",
    "\n",
    "So, I sort the mdist_actuals by Mahalanobis distance and quantile cut the rows into 10 equal sized groups. The observations in the top quantiles should have more 1’s compared to the ones in the bottom. Let’s see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23ccc8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          avg_mahaldist  sum_of_trueclass\n",
      "quantile                                 \n",
      "1              3.765496                33\n",
      "2              6.511026                32\n",
      "3              9.272944                30\n",
      "4             12.209504                20\n",
      "5             14.455050                 4\n",
      "6             15.684493                 4\n",
      "7             17.368633                 3\n",
      "8             18.840714                 1\n",
      "9             21.533159                 2\n",
      "10            23.524055                 1\n"
     ]
    }
   ],
   "source": [
    "# quantile cut in 10 pieces\n",
    "mdist_actuals['quantile'] = pd.qcut(mdist_actuals['mahal'], \n",
    "                                    q=[0, .10, .20, .3, .4, .5, .6, .7, .8, .9, 1], \n",
    "                                    labels=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "# sort by mahalanobis distance\n",
    "mdist_actuals.sort_values('mahal', inplace=True)\n",
    "perc_truths = mdist_actuals.groupby('quantile').agg({'mahal': np.mean, 'true_class': np.sum}).rename(columns={'mahal':'avg_mahaldist', 'true_class':'sum_of_trueclass'})\n",
    "print(perc_truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d95dd4",
   "metadata": {},
   "source": [
    "If you notice above, nearly 90% of the 1’s (malignant cases) fall within the first 40%ile of the Mahalanobis distance. Incidentally, all of these are lower than the critical value pf 14.05. So, let’s the critical value as the cutoff and mark those observations with Mahalanobis distance less than the cutoff as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26897847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix: \n",
      " [[183  29]\n",
      " [ 15 115]]\n",
      "\n",
      "Accuracy Score:  0.8713450292397661\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89       212\n",
      "           1       0.80      0.88      0.84       130\n",
      "\n",
      "    accuracy                           0.87       342\n",
      "   macro avg       0.86      0.87      0.87       342\n",
      "weighted avg       0.88      0.87      0.87       342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Positive if mahalanobis \n",
    "pred_actuals = pd.DataFrame([(int(p), y) for y, p in zip(ytest, clf.predict_proba(xtest) < clf.critical_value)], columns=['pred', 'true'])\n",
    "\n",
    "# Accuracy Metrics\n",
    "truth = pred_actuals.loc[:, 'true']\n",
    "pred = pred_actuals.loc[:, 'pred']\n",
    "print('\\nConfusion Matrix: \\n', confusion_matrix(truth, pred))\n",
    "print('\\nAccuracy Score: ', accuracy_score(truth, pred))\n",
    "print('\\nClassification Report: \\n', classification_report(truth, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff556be5",
   "metadata": {},
   "source": [
    "So, without the knowledge of the benign class, we are able to accurately predict the class of 87% of the observations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
